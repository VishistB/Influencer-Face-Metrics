{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishist/coding/Startup_Assignments/FuelGrowth/Influencer-Face-Metrics/Jupyter_notebooks\n",
      "Face detection and extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "BASE_FOLDER=os.getcwd()\n",
    "print(BASE_FOLDER)\n",
    "UNIQUE_VIDEOS_FOLDER = BASE_FOLDER+\"/unique_videos\"\n",
    "UNIQUE_PERFORMANCE_FOLDER = BASE_FOLDER+\"/unique_performances\"\n",
    "INFLUENCER_FACE_DATA = BASE_FOLDER+\"/influencer_face_data\"\n",
    "FACE_IMG_FOLDER = os.path.join(INFLUENCER_FACE_DATA, \"face_img\")\n",
    "FACE_SCORE_FOLDER = os.path.join(INFLUENCER_FACE_DATA, \"face_score\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(FACE_IMG_FOLDER, exist_ok=True)\n",
    "os.makedirs(FACE_SCORE_FOLDER, exist_ok=True)\n",
    "\n",
    "# Load a pre-trained face detection model (Haar cascade for simplicity)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Process each video in unique_videos\n",
    "for video_file in os.listdir(UNIQUE_VIDEOS_FOLDER):\n",
    "    video_path = os.path.join(UNIQUE_VIDEOS_FOLDER, video_file)\n",
    "    performance_file = os.path.join(UNIQUE_PERFORMANCE_FOLDER, f\"{Path(video_file).stem}.txt\")\n",
    "    \n",
    "    # Skip if performance file doesn't exist\n",
    "    if not os.path.exists(performance_file):\n",
    "        print(f\"Performance file missing for {video_file}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Read the performance score\n",
    "    with open(performance_file, \"r\") as pf:\n",
    "        performance_score = pf.read().strip()\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    face_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Convert frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract face from frame\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Save face image\n",
    "            face_img_name = f\"{Path(video_file).stem}_frame{frame_count}_face{face_count}.jpg\"\n",
    "            face_img_path = os.path.join(FACE_IMG_FOLDER, face_img_name)\n",
    "            cv2.imwrite(face_img_path, face)\n",
    "\n",
    "            # Save performance score\n",
    "            face_score_path = os.path.join(FACE_SCORE_FOLDER, f\"{Path(face_img_name).stem}.txt\")\n",
    "            with open(face_score_path, \"w\") as sf:\n",
    "                sf.write(performance_score)\n",
    "\n",
    "            face_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(\"Face detection and extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Paths\n",
    "BASE_FOLDER=os.getcwd()\n",
    "print(BASE_FOLDER)\n",
    "UNIQUE_VIDEOS_FOLDER = BASE_FOLDER+\"/unique_videos\"\n",
    "UNIQUE_PERFORMANCE_FOLDER = BASE_FOLDER+\"/unique_performances\"\n",
    "INFLUENCER_FACE_DATA = BASE_FOLDER+\"/influencer_face_data\"\n",
    "FACE_IMG_FOLDER = os.path.join(INFLUENCER_FACE_DATA, \"face_img\")\n",
    "FACE_SCORE_FOLDER = os.path.join(INFLUENCER_FACE_DATA, \"face_score\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(FACE_IMG_FOLDER, exist_ok=True)\n",
    "os.makedirs(FACE_SCORE_FOLDER, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "SIMILARITY_THRESHOLD = 0.6  # Threshold for face similarity (lower is stricter)\n",
    "\n",
    "# To store embeddings of saved faces\n",
    "saved_face_embeddings = []\n",
    "\n",
    "# Function to check if a face is unique\n",
    "def is_unique_face(new_embedding, saved_embeddings, threshold=SIMILARITY_THRESHOLD):\n",
    "    for embedding in saved_embeddings:\n",
    "        distance = cosine(embedding, new_embedding)\n",
    "        if distance < threshold:\n",
    "            return False  # Not unique\n",
    "    return True  # Unique\n",
    "\n",
    "# Process each video in unique_videos\n",
    "for video_file in os.listdir(UNIQUE_VIDEOS_FOLDER):\n",
    "    video_path = os.path.join(UNIQUE_VIDEOS_FOLDER, video_file)\n",
    "    performance_file = os.path.join(UNIQUE_PERFORMANCE_FOLDER, f\"{Path(video_file).stem}.txt\")\n",
    "    \n",
    "    # Skip if performance file doesn't exist\n",
    "    if not os.path.exists(performance_file):\n",
    "        print(f\"Performance file missing for {video_file}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Read the performance score\n",
    "    with open(performance_file, \"r\") as pf:\n",
    "        performance_score = pf.read().strip()\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    face_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Detect faces using face_recognition\n",
    "        face_locations = face_recognition.face_locations(frame)  # Detect face bounding boxes\n",
    "        face_encodings = face_recognition.face_encodings(frame, face_locations)  # Compute embeddings\n",
    "\n",
    "        for face_location, face_encoding in zip(face_locations, face_encodings):\n",
    "            # Check if the face is unique\n",
    "            if not is_unique_face(face_encoding, saved_face_embeddings):\n",
    "                continue  # Skip similar face\n",
    "\n",
    "            # Save the face embedding to the list\n",
    "            saved_face_embeddings.append(face_encoding)\n",
    "\n",
    "            # Save the face image\n",
    "            top, right, bottom, left = face_location\n",
    "            face = frame[top:bottom, left:right]\n",
    "            face_img_name = f\"{Path(video_file).stem}_frame{frame_count}_face{face_count}.jpg\"\n",
    "            face_img_path = os.path.join(FACE_IMG_FOLDER, face_img_name)\n",
    "            cv2.imwrite(face_img_path, face)\n",
    "\n",
    "            # Save performance score\n",
    "            face_score_path = os.path.join(FACE_SCORE_FOLDER, f\"{Path(face_img_name).stem}.txt\")\n",
    "            with open(face_score_path, \"w\") as sf:\n",
    "                sf.write(performance_score)\n",
    "\n",
    "            face_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(\"Face detection and extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.39-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (1.13.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vishist/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vishist/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vishist/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/vishist/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vishist/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vishist/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vishist/anaconda3/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishist/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vishist/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vishist/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vishist/anaconda3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in /home/vishist/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/vishist/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/vishist/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/vishist/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in /home/vishist/anaconda3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (69.5.1)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vishist/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vishist/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Downloading ultralytics-8.3.39-py3-none-any.whl (896 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m896.9/896.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, ultralytics-thop, torchvision, ultralytics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 triton-3.1.0 ultralytics-8.3.39 ultralytics-thop-2.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishist/coding/Startup_Assignments/FuelGrowth/Influencer-Face-Metrics/Jupyter_notebooks\n",
      "Face detection and extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "BASE_FOLDER=os.getcwd()\n",
    "print(BASE_FOLDER)\n",
    "UNIQUE_VIDEOS_FOLDER = BASE_FOLDER+\"/unique_videos\"\n",
    "UNIQUE_PERFORMANCE_FOLDER = BASE_FOLDER+\"/unique_performances\"\n",
    "INFLUENCER_FACE_DATA = BASE_FOLDER+\"/influencer_face_data\"\n",
    "FACE_IMG_FOLDER = os.path.join(INFLUENCER_FACE_DATA, \"face_img\")\n",
    "FACE_SCORE_FOLDER = os.path.join(INFLUENCER_FACE_DATA, \"face_score\")\n",
    "\n",
    "os.makedirs(FACE_IMG_FOLDER, exist_ok=True)\n",
    "os.makedirs(FACE_SCORE_FOLDER, exist_ok=True)\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "for video_file in os.listdir(UNIQUE_VIDEOS_FOLDER):\n",
    "    video_path = os.path.join(UNIQUE_VIDEOS_FOLDER, video_file)\n",
    "    performance_file = os.path.join(UNIQUE_PERFORMANCE_FOLDER, f\"{Path(video_file).stem}.txt\")\n",
    "    \n",
    "    if not os.path.exists(performance_file):\n",
    "        print(f\"Performance file missing for {video_file}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    with open(performance_file, \"r\") as pf:\n",
    "        performance_score = pf.read().strip()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    face_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 10 != 0:\n",
    "            continue\n",
    "\n",
    "        results = model.predict(frame, conf=0.5, verbose=False)\n",
    "        detections = results[0].boxes.xyxy\n",
    "\n",
    "        for detection in detections:\n",
    "            x1, y1, x2, y2 = map(int, detection)\n",
    "            face = frame[y1:y2, x1:x2]\n",
    "\n",
    "            face_img_name = f\"{Path(video_file).stem}_frame{frame_count}_face{face_count}.jpg\"\n",
    "            face_img_path = os.path.join(FACE_IMG_FOLDER, face_img_name)\n",
    "            cv2.imwrite(face_img_path, face)\n",
    "\n",
    "            face_score_path = os.path.join(FACE_SCORE_FOLDER, f\"{Path(face_img_name).stem}.txt\")\n",
    "            with open(face_score_path, \"w\") as sf:\n",
    "                sf.write(performance_score)\n",
    "\n",
    "            face_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(\"Face detection and extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishist/coding/Startup_Assignments/FuelGrowth/Influencer-Face-Metrics/Jupyter_notebooks\n",
      "Face detection and extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "BASE_FOLDER=os.getcwd()\n",
    "print(BASE_FOLDER)\n",
    "UNIQUE_VIDEOS_FOLDER = BASE_FOLDER+\"/unique_videos\"\n",
    "UNIQUE_PERFORMANCE_FOLDER = BASE_FOLDER+\"/unique_performances\"\n",
    "INFLUENCER_FACE_DATA = BASE_FOLDER+\"/influencer_face_data\"\n",
    "FACE_IMG_FOLDER = os.path.join(INFLUENCER_FACE_DATA, \"face_img\")\n",
    "FACE_SCORE_FOLDER = os.path.join(INFLUENCER_FACE_DATA, \"face_score\")\n",
    "\n",
    "os.makedirs(FACE_IMG_FOLDER, exist_ok=True)\n",
    "os.makedirs(FACE_SCORE_FOLDER, exist_ok=True)\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "for video_file in os.listdir(UNIQUE_VIDEOS_FOLDER):\n",
    "    video_path = os.path.join(UNIQUE_VIDEOS_FOLDER, video_file)\n",
    "    performance_file = os.path.join(UNIQUE_PERFORMANCE_FOLDER, f\"{Path(video_file).stem}.txt\")\n",
    "    \n",
    "    if not os.path.exists(performance_file):\n",
    "        print(f\"Performance file missing for {video_file}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    with open(performance_file, \"r\") as pf:\n",
    "        performance_score = pf.read().strip()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    face_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 10 != 0:\n",
    "            continue\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = face_detector(gray_frame)\n",
    "\n",
    "        for face in faces:\n",
    "            h, w, _ = frame.shape\n",
    "            x1 = max(0, face.left())\n",
    "            y1 = max(0, face.top())\n",
    "            x2 = min(w, face.right())\n",
    "            y2 = min(h, face.bottom())\n",
    "\n",
    "            if x1 < x2 and y1 < y2:\n",
    "                face_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                face_img_name = f\"{Path(video_file).stem}_frame{frame_count}_face{face_count}.jpg\"\n",
    "                face_img_path = os.path.join(FACE_IMG_FOLDER, face_img_name)\n",
    "                cv2.imwrite(face_img_path, face_crop)\n",
    "\n",
    "                face_score_path = os.path.join(FACE_SCORE_FOLDER, f\"{Path(face_img_name).stem}.txt\")\n",
    "                with open(face_score_path, \"w\") as sf:\n",
    "                    sf.write(performance_score)\n",
    "\n",
    "                face_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(\"Face detection and extraction completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
